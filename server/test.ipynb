{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: C:\\Main Storage\\Job\\job_calvin\\audio_sample_trim1.wav\n",
      "------------------------------\n",
      "Success! Found 6 speech segments.\n",
      "Error:\n",
      "module 'torchaudio' has no attribute 'info'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
    "\n",
    "# --- 1. OVERRIDE THE READ FUNCTION ---\n",
    "def read_audio_safe(path: str, target_sr: int = 16000):\n",
    "    \"\"\"\n",
    "    Reads a WAV file using 'soundfile' (bypassing torchaudio backend issues)\n",
    "    and converts it to a standardized Torch Tensor for VAD.\n",
    "    \"\"\"\n",
    "    # Read directly with soundfile (No FFmpeg needed for WAV)\n",
    "    data, samplerate = sf.read(path)\n",
    "\n",
    "    # Convert to Tensor\n",
    "    audio_tensor = torch.FloatTensor(data)\n",
    "\n",
    "    # Handle Stereo (Convert to Mono if needed)\n",
    "    # VAD models expect (1, N) or (N,)\n",
    "    if len(audio_tensor.shape) > 1:\n",
    "        # If shape is [Samples, Channels], average them to get Mono\n",
    "        audio_tensor = audio_tensor.mean(dim=1) \n",
    "    \n",
    "    # Add dimension if needed: [N] -> [1, N]\n",
    "    if audio_tensor.ndim == 1:\n",
    "        audio_tensor = audio_tensor.unsqueeze(0)\n",
    "\n",
    "    # --- RESAMPLING ---\n",
    "    # Silero VAD works best at 16000Hz. If the file is 44100Hz or 48000Hz, we must resample.\n",
    "    if samplerate != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=samplerate, new_freq=target_sr)\n",
    "        audio_tensor = resampler(audio_tensor)\n",
    "\n",
    "    return audio_tensor\n",
    "\n",
    "# --- 2. LOAD VAD MODEL ---\n",
    "vad_model = load_silero_vad()\n",
    "\n",
    "# --- 3. RUN ANALYSIS ---\n",
    "test_audio_path = r\"C:\\Main Storage\\Job\\job_calvin\\audio_sample_trim1.wav\"\n",
    "\n",
    "try:\n",
    "    print(f\"Reading: {test_audio_path}\")\n",
    "    \n",
    "    # USE THE SAFE READ FUNCTION\n",
    "    wav = read_audio_safe(test_audio_path)\n",
    "    \n",
    "    # Run VAD\n",
    "    speech_timestamps = get_speech_timestamps(\n",
    "        wav, \n",
    "        model, \n",
    "        threshold=0.5, \n",
    "        return_seconds=True\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Success! Found {len(speech_timestamps)} speech segments.\")\n",
    "    \n",
    "    # Invert logic to find silence (Your original logic)\n",
    "    silence_segments = []\n",
    "    current_time = 0.0\n",
    "    \n",
    "    # Calculate total duration for the final cut\n",
    "    total_duration = wav.shape[1] / 16000 \n",
    "\n",
    "    for speech in speech_timestamps:\n",
    "        if speech['start'] > current_time:\n",
    "            silence_segments.append([round(current_time, 2), round(speech['start'], 2)])\n",
    "        current_time = speech['end']\n",
    "        \n",
    "    if current_time < total_duration:\n",
    "        silence_segments.append([round(current_time, 2), round(total_duration, 2)])\n",
    "\n",
    "    print(\"Silence Segments (Seconds):\")\n",
    "    print(silence_segments)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\")\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
